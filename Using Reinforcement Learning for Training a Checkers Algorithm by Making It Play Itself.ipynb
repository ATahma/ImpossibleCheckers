{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Ali Tahmasebi, Marianopolis College, May 2019, Part of the Epreuve Synthese \n",
    "In this project, we use a [_Checkers_ (Also known as _Draughts_)](https://en.wikipedia.org/wiki/Draughts) API that is written from scratch to build an algorithm that, after playing with itself for thousands of times, is able to develop a __Policy__ function withing its agent. The use of this __Policy__ function, as the name suggests, is to lead the computer to ideally win games against human players. To implement this algorithm, the principle of __Reinforcement Learning__ is used, which is a popular [_Machine Learning_](https://en.wikipedia.org/wiki/Machine_learning) area that takes inspiration from human psychology to try to understand machine beahviour. Basically, when the computer performs an action, the algorithm sets a reward for the action (or set of actions). The computer will store the reward and shape its future behaviour based on the reward. Very similarly to humans, the computer is eager to go towards the biggest reward possible and will learn overtime on how to get there as fast as possible. One can link this human-like behaviour of algorithms to recent attemps by Artificial Intelligence researchers to provide explanation about what really happens inside an algorithm, and human behaviour is a good stop to start from <sup>1</sup>. For example, researchers using an image classification [_Artificial Neural Network_](https://en.wikipedia.org/wiki/Artificial_neural_network) found out that the algorithm immediately gains a sense of [_Adaptive Numerosity_](https://en.wikipedia.org/wiki/Numerosity_adaptation_effect) <sup>2</sup>, like humans or animals. The algorithm used here is thought to know how to win the game, without knowing how to actually play it. This checkers program directs its behaviour based on the reward function and one can, on the other hand, make an algorithm that purposefuly loses or even makes it hard to stop it from losing. Bearing in mind the prior examples given, one can argue that algorithms such as this checkers algorithm should be studied from a social-scientific point of view, by starting to assuming them to be human-like in behaviour. \n",
    " \n",
    "### Keywords: Machine Learning, Checkers, Reinforcement Learning, Explainable Artificial Intelligence.\n",
    " \n",
    "### Works Cited\n",
    "\n",
    "1.Tim Miller. \"Explanation in artificial intelligence: Insights from the social sciences\"._Artificial Intelligence_, Volume 267, 2019, Pages 1-38, ISSN 0004-3702. https://doi.org/10.1016/j.artint.2018.07.007.(http://www.sciencedirect.com/science/article/pii/S0004370218305988).\n",
    "2.Khaled Nasr, Pooja Viswanathan, Andreas Nieder. \"Number detectors spontaneously emerge in a deep neural network designed for visual object recognition\". _Science Advances_, 08 May 2019, eaav7903."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
